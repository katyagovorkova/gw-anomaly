{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "from gwpy.timeseries import TimeSeries\n",
    "from astropy import units as u\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.grid'] = False\n",
    "from matplotlib.colors import LinearSegmentedColormap, TwoSlopeNorm\n",
    "from models import LinearModel, GwakClassifier\n",
    "from evaluate_data import full_evaluation\n",
    "import json\n",
    "import matplotlib\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import conv1d\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.signal import welch\n",
    "import pickle\n",
    "from config import (\n",
    "    CHANNEL,\n",
    "    GPU_NAME,\n",
    "    SEGMENT_OVERLAP,\n",
    "    SAMPLE_RATE,\n",
    "    BANDPASS_HIGH,\n",
    "    BANDPASS_LOW,\n",
    "    FACTORS_NOT_USED_FOR_FM,\n",
    "    MODELS_LOCATION,\n",
    "    SEG_NUM_TIMESTEPS,\n",
    "    CLASS_ORDER\n",
    "    )\n",
    "from helper_functions import (\n",
    "    far_to_metric, \n",
    "    compute_fars, \n",
    "    load_gwak_models, \n",
    "    joint_heuristic_test, \n",
    "    combine_freqcorr\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# export CUDA_LAUNCH_BLOCKING=1\n",
    "GPU_NAME = 'cuda:0'\n",
    "DEVICE = torch.device(GPU_NAME)\n",
    "# DEVICE=torch.device(\"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasedModel, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(3, 1)\n",
    "        self.layer2_1 = nn.Linear(1, 1)\n",
    "        self.layer2_2 = nn.Linear(1, 1)\n",
    "        self.layer2_3 = nn.Linear(1, 1)\n",
    "        \n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.activation(self.layer1(x[:, :3]))\n",
    "        x2_1 = self.activation(self.layer2_1(x[:, 3:4]))\n",
    "        x2_2 = self.activation(self.layer2_1(x[:, 4:5]))\n",
    "        x2_3 = self.activation(self.layer2_1(x[:, 5:6]))\n",
    "        return x1 * x2_1 * x2_2 * x2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(gwak_values):\n",
    "    result = np.zeros((gwak_values.shape[0], 3))\n",
    "    for i, pair in enumerate([[3, 4], [9, 10], [12, 13]]):\n",
    "        a, b = pair\n",
    "        ratio_a = (np.abs(gwak_values[:, a]) + 2) / (np.abs(gwak_values[:, b]) + 2)\n",
    "        ratio_b = (np.abs(gwak_values[:, b]) + 2) / (np.abs(gwak_values[:, a]) + 2)\n",
    "\n",
    "        ratio = np.maximum(ratio_a, ratio_b)\n",
    "        result[:, i] = ratio\n",
    "    return result\n",
    "\n",
    "def compute_signal_strength_chop_sep(x, y):\n",
    "    psd0 = welch(x)[1]\n",
    "    psd1 = welch(y)[1]\n",
    "    HLS = np.log(np.sum(psd0))\n",
    "    LLS = np.log(np.sum(psd1))\n",
    "    return HLS, LLS\n",
    "    \n",
    "def shifted_pearson(H, L, H_start, H_end, maxshift=int(10*4096/1000)):\n",
    "    # works for one window at a time\n",
    "    Hs = H[H_start:H_end]\n",
    "    minval = 1\n",
    "    for shift in range(-maxshift, maxshift):\n",
    "        Ls = L[H_start+shift:H_end+shift]\n",
    "        #minval = min(pearsonr(Hs, Ls)[0], minval)\n",
    "        p = pearsonr(Hs, Ls)[0]\n",
    "        if p < minval:\n",
    "            minval = p\n",
    "            shift_idx = shift\n",
    "\n",
    "    return minval, shift_idx\n",
    "\n",
    "def parse_strain(x):\n",
    "    # take strain, compute the long sig strenght & pearson\n",
    "    # split it up, do the same thing for short\n",
    "    long_pearson, shift_idx = shifted_pearson(x[0], x[1], 50, len(x[0])-50)\n",
    "    #long_sig_strength = compute_signal_strength_chop(x[0, 50:-50], x[1, 50+shift_idx:len(x[0])-50+shift_idx] )\n",
    "    HSS, LSS = compute_signal_strength_chop_sep(x[0, 50:-50], x[1, 50+shift_idx:len(x[0])-50+shift_idx])\n",
    "    return long_pearson, HSS, LSS\n",
    "\n",
    "def parse_gwtc_catalog(path, mingps=None, maxgps=None):\n",
    "    gwtc = np.loadtxt(path, delimiter=\",\", dtype=\"str\")\n",
    "\n",
    "    pulled_data = np.zeros((gwtc.shape[0]-1, 3))\n",
    "    for i, elem in enumerate(gwtc[1:]): #first row is just data value description\n",
    "        pulled_data[i] = [float(elem[4]), float(elem[13]), float(elem[34])]\n",
    "\n",
    "    if mingps != None:\n",
    "        assert maxgps != None\n",
    "        pulled_data = pulled_data[np.logical_and(pulled_data[:, 0]<maxgps, pulled_data[:, 0]>mingps)]\n",
    "    return pulled_data\n",
    "\n",
    "def find_segment(gps, segs):\n",
    "    for seg in segs:\n",
    "        a, b = seg\n",
    "        if a < gps and b > gps:\n",
    "            return seg\n",
    "\n",
    "def sig_prob_function(evals, scale=40):\n",
    "    sigmoid = lambda x: 1/(1+np.exp(-x))\n",
    "    #sigmoid = lambda x: 1/(1+np.exp(-(x-0.3)))\n",
    "    return 1-(sigmoid(scale * (evals-0.5)))\n",
    "\n",
    "def get_far(score, sort_eval):\n",
    "    ind = np.searchsorted(sort_eval, score)\n",
    "    if ind == len(sort_eval):\n",
    "        ind -= 1\n",
    "    #N = len(sort_eval)\n",
    "    units = 10000*3.15e7\n",
    "    return ind/units\n",
    "\n",
    "def make_eval_chunks(a, b, dur):\n",
    "    '''\n",
    "    Split up into one-hour chunks to normalize the whitening duration\n",
    "    a, b - ints\n",
    "    A, B - strings\n",
    "\n",
    "    output - only care about the strings\n",
    "    '''\n",
    "    n_full_chunks = (b-a)//dur\n",
    "\n",
    "    out = []\n",
    "    for n in range(1, n_full_chunks+1):\n",
    "        out.append([str(a+(n-1)*dur), str(a+n*dur)])\n",
    "\n",
    "    #ending chunk, but still make it one hour\n",
    "    out.append([str(b-dur), str(b)])\n",
    "    return out\n",
    "\n",
    "def event_clustering(indices, scores, spacing, device):\n",
    "    '''\n",
    "    Group the evaluations into events, i.e. treat a consecutive sequence\n",
    "    of low anomaly score as a single event\n",
    "    '''\n",
    "\n",
    "    clustered = []\n",
    "    idxs = indices.detach().cpu().numpy()\n",
    "    cluster = []\n",
    "    for i, elem in enumerate(idxs):\n",
    "        # to move onto next cluster\n",
    "        if i != 0:\n",
    "            dist = elem - idxs[i-1]\n",
    "            if dist > spacing:\n",
    "                #make a new cluster\n",
    "                clustered.append(cluster)\n",
    "                cluster = [] # and initiate a new one\n",
    "        cluster.append(elem)\n",
    "    clustered.append(cluster) # last one isn't captured, since we haven't moved on\n",
    "    final_points = []\n",
    "    for cluster in clustered:\n",
    "        # take the one with the lowest score (most significant)\n",
    "        bestscore = 10\n",
    "        bestval = None\n",
    "        for elem in cluster:\n",
    "            if scores[elem] < bestscore:\n",
    "                bestscore = scores[elem]\n",
    "                bestval = elem\n",
    "        final_points.append(bestval)\n",
    "    return torch.from_numpy(np.array(final_points)).int().to(device)\n",
    "\n",
    "def extract_chunks(strain_data, timeslide_num, important_points, device,\n",
    "                    roll_amount = SEG_NUM_TIMESTEPS, window_size=1024):\n",
    "    '''\n",
    "    Important points are indicies into thestrain_data\n",
    "    '''\n",
    "    L_shift = timeslide_num*roll_amount\n",
    "    timeslide_len = strain_data.shape[1]\n",
    "    edge_check_passed = []\n",
    "    fill_strains = np.zeros((len(important_points), 2, window_size*2))\n",
    "    for idx, point in enumerate(important_points):\n",
    "        # check that the point is not on the edge\n",
    "        edge_check_passed.append(not(point < window_size * 2 or timeslide_len - point < window_size*2))\n",
    "        if not(point < window_size * 2 or timeslide_len - point < window_size*2):\n",
    "            H_selection = strain_data[0, point-window_size:point+window_size]\n",
    "\n",
    "            # if the livingston points overflow, the modulo should bring them\n",
    "            # into the right location. also data is clipped //1000 * 1000\n",
    "            # which is divisible by 200, so it should work\n",
    "            L_start = (point-window_size+L_shift) % timeslide_len\n",
    "            L_end = (point+window_size+L_shift) % timeslide_len\n",
    "\n",
    "            L_selection = strain_data[1, L_start:L_end]\n",
    "\n",
    "            fill_strains[idx, 0, :] = H_selection\n",
    "            fill_strains[idx, 1, :] = L_selection\n",
    "\n",
    "    return fill_strains, edge_check_passed\n",
    "\n",
    "def whiten_bandpass_resample(\n",
    "        start_point,\n",
    "        end_point,\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        bandpass_low=BANDPASS_LOW,\n",
    "        bandpass_high=BANDPASS_HIGH,\n",
    "        shift=None):\n",
    "\n",
    "    start_point, end_point = int(start_point)-10, int(end_point)+10\n",
    "    strainL1 = TimeSeries.get(f\"L1:{CHANNEL}\", start_point, end_point)\n",
    "    strainH1 = TimeSeries.get(f\"H1:{CHANNEL}\", start_point, end_point) #f'H1:{CHANNEL}',\n",
    "\n",
    "    strainL1 = strainL1.resample(sample_rate).bandpass(bandpass_low, bandpass_high)\n",
    "    strainL1 = strainL1.whiten()\n",
    "\n",
    "    strainH1 = strainH1.resample(sample_rate).bandpass(bandpass_low, bandpass_high)\n",
    "    strainH1 = strainH1.whiten()\n",
    "\n",
    "    return [strainH1, strainL1]\n",
    "\n",
    "def whiten_bandpass_resample_new_order(\n",
    "        start_point,\n",
    "        end_point,\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        bandpass_low=BANDPASS_LOW,\n",
    "        bandpass_high=BANDPASS_HIGH,\n",
    "        shift=None):\n",
    "\n",
    "    device = torch.device(GPU_NAME)\n",
    "\n",
    "    start_point, end_point = int(start_point)-10, int(end_point)+10\n",
    "    strainL1_0 = TimeSeries.get(f\"L1:{CHANNEL}\", start_point, end_point)#f'L1:{CHANNEL}',\n",
    "    strainH1_0 = TimeSeries.get(f\"H1:{CHANNEL}\", start_point, end_point)#f'H1:{CHANNEL}',\n",
    "\n",
    "    strainL1 = strainL1_0.resample(sample_rate).whiten().bandpass(bandpass_low, bandpass_high)#.resample(sample_rate).whiten()\n",
    "    strainH1 = strainH1_0.resample(sample_rate).whiten().bandpass(bandpass_low, bandpass_high)#.whiten()#.resample(sample_rate).whiten()\n",
    "\n",
    "    return [strainH1, strainL1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evals(data_, model_path, savedir, start_point,\n",
    "              gwpy_timeseries, neworder_clean=None, neworder_raw=None,\n",
    "              manual_eval_times=None, metric=None):\n",
    "    # heur_model_path = \"/home/katya.govorkova/gwak-paper-final-models/trained/model_heuristic.h5\"\n",
    "    # model_heuristic = BasedModel().to(DEVICE)\n",
    "    # model_heuristic.load_state_dict(torch.load(heur_model_path, map_location=DEVICE))\n",
    "\n",
    "    # split the data into 1-hour chunks to fit in memory best\n",
    "    eval_at_once_len = int(3600)\n",
    "    N_one_hour_splits = int(data_.shape[1]//(eval_at_once_len*SAMPLE_RATE) + 1)\n",
    "    print(\"N splits:\", N_one_hour_splits)\n",
    "\n",
    "    for hour_split in range(N_one_hour_splits):\n",
    "        start = int(hour_split*SAMPLE_RATE*eval_at_once_len)\n",
    "        end = int(min(data_.shape[1], (hour_split+1)*SAMPLE_RATE*eval_at_once_len))\n",
    "        print(start, end)\n",
    "        if end - 10 < start:\n",
    "            return None\n",
    "        data = data_[:, start:end]\n",
    "\n",
    "        model_types = [\"bbh.pt\",\n",
    "                       \"sglf.pt\",\n",
    "                       \"sghf.pt\",\n",
    "                       \"background.pt\",\n",
    "                       \"glitches.pt\"]\n",
    "\n",
    "        model_paths = []\n",
    "        for elem in model_types:\n",
    "            model_paths.append(model_path + elem)\n",
    "\n",
    "        gwak_models = load_gwak_models(model_paths, DEVICE, GPU_NAME)\n",
    "\n",
    "        norm_factors = np.load(f\"/home/katya.govorkova/gwak-paper-final-models/trained/norm_factor_params.npy\")\n",
    "        fm_model_path = (\"/home/katya.govorkova/gwak-paper-final-models/trained/fm_model.pt\")\n",
    "\n",
    "        orig_kernel = 50\n",
    "        kernel_len = int(orig_kernel * 5/SEGMENT_OVERLAP)\n",
    "        kernel = torch.ones((1, kernel_len)).float().to(DEVICE)/kernel_len\n",
    "        kernel = kernel[None, :, :]\n",
    "        heuristics_tests = True\n",
    "\n",
    "        fm_model = LinearModel(21-len(FACTORS_NOT_USED_FOR_FM)).to(DEVICE)\n",
    "        fm_model.load_state_dict(torch.load(\n",
    "            fm_model_path, map_location=GPU_NAME))\n",
    "\n",
    "        linear_weights = fm_model.layer.weight.detach()\n",
    "        bias_value = fm_model.layer.bias.detach()\n",
    "        linear_weights[:, -2] += linear_weights[:, -1]\n",
    "        linear_weights = linear_weights[:, :-1]\n",
    "        norm_factors = norm_factors[:, :-1]\n",
    "\n",
    "        orig_kernel = 50\n",
    "        kernel_len = int(orig_kernel * 5/SEGMENT_OVERLAP)\n",
    "        kernel = torch.ones((1, kernel_len)).float().to(DEVICE)/kernel_len\n",
    "        kernel = kernel[None, :, :]\n",
    "        heuristics_tests = True\n",
    "\n",
    "        mean_norm = torch.from_numpy(norm_factors[0]).to(DEVICE)\n",
    "        std_norm = torch.from_numpy(norm_factors[1]).to(DEVICE)\n",
    "\n",
    "        final_values, midpoints, original, recreated = full_evaluation(\n",
    "                        data[None, :, :], model_paths, DEVICE,\n",
    "                        return_midpoints=True, return_recreations=True,\n",
    "                        loaded_models=gwak_models, grad_flag=False)\n",
    "\n",
    "        final_values = final_values[0]\n",
    "\n",
    "        # Set the threshold here\n",
    "        FAR_2days = -1 # lowest FAR bin we want to worry about\n",
    "\n",
    "        # Inference to save scores (final metric) and scaled_evals (GWAK space * weights unsummed)\n",
    "        final_values_slx = (final_values - mean_norm)/std_norm\n",
    "        scaled_evals = torch.multiply(final_values_slx, linear_weights[None, :])[0, :]\n",
    "\n",
    "        scores = (scaled_evals.sum(axis=1) + bias_value)[:, None]\n",
    "        scaled_evals = conv1d(scaled_evals.transpose(0, 1).float()[:, None, :],\n",
    "            kernel, padding=\"same\").transpose(0, 1)[0].transpose(0, 1)\n",
    "        smoothed_scores = conv1d(scores.transpose(0, 1).float()[:, None, :],\n",
    "            kernel, padding=\"same\").transpose(0, 1)[0].transpose(0, 1)\n",
    "        indices = torch.where(smoothed_scores < FAR_2days)[0]\n",
    "\n",
    "        manual_eval_times = torch.tensor(manual_eval_times).to(indices.device)\n",
    "        if manual_eval_times[0] > start_point:\n",
    "            manual_eval_times -= start_point\n",
    "\n",
    "        manual_eval_indices = torch.zeros_like(manual_eval_times)\n",
    "\n",
    "        for i, eval_time in enumerate(manual_eval_times):\n",
    "            eval_time = eval_time * SAMPLE_RATE\n",
    "            insert_location = torch.searchsorted(torch.from_numpy(midpoints).to(eval_time.device), eval_time)\n",
    "            print(414, torch.searchsorted(torch.from_numpy(midpoints).to(eval_time.device), eval_time))\n",
    "            manual_eval_indices[i] = insert_location\n",
    "\n",
    "\n",
    "\n",
    "        if len(indices) == 0: continue # Didn't find anything\n",
    "\n",
    "        indices = event_clustering(indices, smoothed_scores, 5*SAMPLE_RATE/SEGMENT_OVERLAP, DEVICE) # 5 seconds\n",
    "        indices = torch.cat([indices, manual_eval_indices]).int()\n",
    "        filtered_final_score = smoothed_scores.index_select(0, indices)\n",
    "        filtered_final_scaled_evals = scaled_evals.index_select(0, indices)\n",
    "\n",
    "        indices = indices.detach().cpu().numpy()\n",
    "        # extract important \"events\" with indices\n",
    "        timeslide_chunks, edge_check_filter = extract_chunks(data, 0, # 0 - timeslide number 0 (no shifting happening)\n",
    "                                            midpoints[indices],\n",
    "                                            DEVICE, window_size=1024) # 0.25 seconds on either side\n",
    "                                                                    # so it should come out to desired 0.5\n",
    "\n",
    "        filtered_final_scaled_evals = filtered_final_scaled_evals.detach().cpu().numpy()\n",
    "        filtered_final_score = filtered_final_score.detach().cpu().numpy()\n",
    "\n",
    "        filtered_final_scaled_evals = filtered_final_scaled_evals[edge_check_filter]\n",
    "        filtered_final_score = filtered_final_score[edge_check_filter]\n",
    "        timeslide_chunks = timeslide_chunks[edge_check_filter]\n",
    "        indices = indices[edge_check_filter]\n",
    "\n",
    "        filtered_timeslide_chunks = timeslide_chunks\n",
    "\n",
    "        heuristics_tests = False\n",
    "        if heuristics_tests:\n",
    "            N_initial = len(filtered_final_score)\n",
    "            passed_heuristics = []\n",
    "            gwak_filtered = extract(filtered_final_scaled_evals)\n",
    "            for i, strain_segment in enumerate(timeslide_chunks):\n",
    "                strain_feats = parse_strain(strain_segment)\n",
    "                together = np.concatenate([strain_feats, gwak_filtered[i]])\n",
    "                print(433, \"together\", together, filtered_final_score[i])\n",
    "                res = model_heuristic(torch.from_numpy(together[None, :]).float().to(DEVICE)).item()\n",
    "                #passed_heuristics.append(res<0.46)\n",
    "                #res -= 0.1\n",
    "\n",
    "                res_sigmoid = sig_prob_function(res)\n",
    "                #print(res, res_sigmoid, filtered_final_score[i])\n",
    "                final_final = res_sigmoid * filtered_final_score[i]\n",
    "                #print(res, res_sigmoid, filtered_final_score[i])\n",
    "                filtered_final_score[i] *= res_sigmoid\n",
    "                print(res, res_sigmoid, filtered_final_score[i])\n",
    "                passed_heuristics.append(final_final[0] < -1.) #[0] since it was saving arrays(arrays)\n",
    "\n",
    "\n",
    "            filtered_final_scaled_evals = filtered_final_scaled_evals[passed_heuristics]\n",
    "            filtered_final_score = filtered_final_score[passed_heuristics]\n",
    "            filtered_timeslide_chunks = timeslide_chunks[passed_heuristics]\n",
    "            indices = indices[passed_heuristics]\n",
    "\n",
    "            print(f\"Fraction removed by heuristics test {N_initial -len(filtered_final_score)}/{N_initial}\")\n",
    "        # rename them for less confusion, easier typing\n",
    "        gwak_values = filtered_final_scaled_evals\n",
    "        fm_scores = filtered_final_score\n",
    "        strain_chunks = filtered_timeslide_chunks\n",
    "\n",
    "        if strain_chunks.shape[0] == 0: continue\n",
    "        # plotting all these significant events\n",
    "        n_points = strain_chunks.shape[2]\n",
    "\n",
    "        scaled_evals = scaled_evals.cpu().numpy()\n",
    "        scaled_evals = combine_freqcorr(scaled_evals)\n",
    "        bias_value = bias_value.cpu().numpy()\n",
    "        smoothed_scores = smoothed_scores.cpu().numpy()\n",
    "\n",
    "        for j in range(len(gwak_values)):\n",
    "            # Create two figures\n",
    "            fig1, axs1 = plt.subplots(4, 1, figsize=(10, 12) ) #, sharex=True)  # Strain and GWAK values (shared x-axis)\n",
    "            # fig2, axs2 = plt.subplots(2, 1, figsize=(10, 8), sharex=True, constrained_layout=True)  # Hanford and Livingston Q-transforms (shared y-axis)\n",
    "        \n",
    "            loudest = indices[j]\n",
    "            left_edge = 1024 // SEGMENT_OVERLAP\n",
    "            right_edge = 1024 // SEGMENT_OVERLAP\n",
    "            quak_evals_ts = np.linspace(0, (left_edge + right_edge) * SEGMENT_OVERLAP / SAMPLE_RATE, left_edge + right_edge)\n",
    "        \n",
    "            labels = ['Background', 'Background', 'BBH', 'BBH', 'Glitch', 'Glitch', 'SG 64-512 Hz', 'SG 64-512 Hz', 'SG (512-1024 Hz)', 'SG (512-1024 Hz)', 'Frequency correlation']\n",
    "            cols = [\n",
    "                \"#f4a3c1\",  # Background (Soft Pink)\n",
    "                \"#ffd700\",  # BBH (Yellow - Gold)\n",
    "                \"#2a9d8f\",  # Glitch (Emerald Green)\n",
    "                \"#708090\",  # SGLF (Light Slate Gray)\n",
    "                \"#00bfff\",  # SGHF (Deep Sky Blue)\n",
    "                \"#cd5c5c\",  # Freq Corr (Indian Red)\n",
    "                \"#006400\",  # Final Metric (Dark Green)\n",
    "                \"#daa520\",  # Hanford (Goldenrod)\n",
    "                \"#ff6347\",  # Livingston (Tomato)\n",
    "            ]\n",
    "            # Strain plot\n",
    "            strain_ts = np.linspace(0, len(strain_chunks[j, 0, :]) / SAMPLE_RATE, len(strain_chunks[j, 0, :]))\n",
    "            axs1[2].plot(strain_ts, strain_chunks[j, 0, :], label='Hanford', alpha=0.8, c=\"#6c5b7b\")\n",
    "            axs1[2].plot(strain_ts, strain_chunks[j, 1, :], label='Livingston', alpha=0.8, c=\"#f29e4c\")\n",
    "            axs1[2].set_ylabel('Strain', fontsize=14)\n",
    "            axs1[2].legend()\n",
    "            # axs1[0].set_title(f'GPS time: {start_point + midpoints[loudest] / SAMPLE_RATE + hour_split * eval_at_once_len:.1f}')\n",
    "            # Remove x-axis ticks\n",
    "            axs1[2].tick_params(axis='x', which='both', bottom=False, top=False)\n",
    "            axs1[2].set_xticklabels([])\n",
    "\n",
    "            # GWAK values plot\n",
    "            for i in range(scaled_evals.shape[1]):\n",
    "                line_type = \"-\" if i % 2 == 0 else \"--\"\n",
    "                axs1[3].plot(\n",
    "                    1000 * quak_evals_ts,\n",
    "                    scaled_evals[loudest - left_edge:loudest + right_edge, i],\n",
    "                    label=labels[i] if i % 2 == 0 or labels[i] in [\"Frequency correlation\"] else None,\n",
    "                    c=cols[i // 2],\n",
    "                    linestyle=line_type\n",
    "                )\n",
    "            axs1[3].plot(\n",
    "                1000 * quak_evals_ts,\n",
    "                smoothed_scores[loudest - left_edge:loudest + right_edge] - bias_value,\n",
    "                label='Final metric',\n",
    "                c='black'\n",
    "            )\n",
    "            axs1[3].set_xlabel(\"Time (ms)\", fontsize=14)\n",
    "            axs1[3].set_ylabel(\"Final metric contributions\", fontsize=14)\n",
    "            axs1[3].legend()\n",
    "                    \n",
    "            # Define a custom colormap with pink in the middle\n",
    "            custom_cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"#1f77b4\", \"#f4a3c1\", \"#ffd700\"], N=256)\n",
    "            \n",
    "            # Define shared color scale range and normalization (pink in the middle)\n",
    "            vmin, vcenter, vmax = 0, 12.5, 25  # Pink at 12.5, scale from 0 to 25\n",
    "            norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "            \n",
    "            # Hanford and Livingston Q-Transforms\n",
    "            p = midpoints[loudest]\n",
    "            left_edge = 1024\n",
    "            right_edge = 1024\n",
    "            q_edge = int(7.5 * 4096)\n",
    "            \n",
    "            H_strain = gwpy_timeseries[0][\n",
    "                p - left_edge - q_edge + eval_at_once_len * hour_split * SAMPLE_RATE:\n",
    "                p + right_edge + q_edge + eval_at_once_len * hour_split * SAMPLE_RATE\n",
    "            ]\n",
    "            L_strain = gwpy_timeseries[1][\n",
    "                p - left_edge - q_edge + eval_at_once_len * hour_split * SAMPLE_RATE:\n",
    "                p + right_edge + q_edge + eval_at_once_len * hour_split * SAMPLE_RATE\n",
    "            ]\n",
    "            \n",
    "            t0 = H_strain.t0.value\n",
    "            dt = H_strain.dt.value\n",
    "            H_hq = H_strain.q_transform(outseg=(t0 + q_edge * dt, t0 + q_edge * dt + (left_edge + right_edge) * dt), whiten=False)\n",
    "            L_hq = L_strain.q_transform(outseg=(t0 + q_edge * dt, t0 + q_edge * dt + (left_edge + right_edge) * dt), whiten=False)\n",
    "            \n",
    "            f = np.array(H_hq.yindex)\n",
    "            t = np.array(H_hq.xindex)\n",
    "            t -= t[0]\n",
    "            \n",
    "            # Create the Q-Transform plots\n",
    "            im_H = axs1[0].pcolormesh(\n",
    "                t * 1000,\n",
    "                f,\n",
    "                np.array(H_hq).T,\n",
    "                cmap=custom_cmap,\n",
    "                norm=norm,\n",
    "                shading=\"auto\"\n",
    "            )\n",
    "            axs1[0].set_yscale(\"log\")\n",
    "            axs1[0].set_ylabel(\"Frequency (Hz)\", fontsize=14)\n",
    "            # axs1[1].set_title(\"Hanford Q-Transform\", fontsize=14)\n",
    "            axs1[1].tick_params(axis='x', which='both', bottom=False, top=False)\n",
    "            axs1[0].tick_params(axis='x', which='both', bottom=False, top=False)\n",
    "            axs1[1].set_xticklabels([])\n",
    "            axs1[0].set_xticklabels([])\n",
    "\n",
    "            \n",
    "            im_L = axs1[1].pcolormesh(\n",
    "                t * 1000,\n",
    "                f,\n",
    "                np.array(L_hq).T,\n",
    "                cmap=custom_cmap,\n",
    "                norm=norm,\n",
    "                shading=\"auto\"\n",
    "            )\n",
    "            axs1[1].set_yscale(\"log\")\n",
    "            # axs1[1].set_xlabel(\"Time (ms)\", fontsize=12)\n",
    "            axs1[1].set_ylabel(\"Frequency (Hz)\", fontsize=14)\n",
    "            # axs1[1].set_title(\"Livingston Q-Transform\", fontsize=14)\n",
    "            \n",
    "            # Add shared colorbar\n",
    "            cbar = fig1.colorbar(\n",
    "                im_H,\n",
    "                ax=axs1[0],\n",
    "                location=\"top\",\n",
    "                pad=0.05,\n",
    "                # shrink=0.9,\n",
    "                aspect=30\n",
    "            )\n",
    "            cbar.set_label(\"Spectral Power\", fontsize=12)\n",
    "            \n",
    "            # Adjust layout\n",
    "            fig1.tight_layout()\n",
    "            \n",
    "\n",
    "\n",
    "            # Save figures\n",
    "            base = f'{savedir}/{start_point + p / SAMPLE_RATE:.3f}_{fm_scores[j][0]:.2f}'\n",
    "            fig1.savefig(f'{base}_strain_gwak_values.png', dpi=300, bbox_inches=\"tight\")\n",
    "            # plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n",
    "            # fig2.savefig(f'{base}_q_transforms.png', dpi=300, bbox_inches=\"tight\")\n",
    "            plt.close(fig1)\n",
    "            # plt.close(fig2)\n",
    "            \n",
    "            # Save data\n",
    "            np.savez(\n",
    "                f\"{base}.npz\",\n",
    "                {\n",
    "                    \"strain\": [strain_ts, strain_chunks[j]],\n",
    "                    \"gwak_values\": [1000 * quak_evals_ts, smoothed_scores[loudest - left_edge:loudest + right_edge] - bias_value],\n",
    "                    \"H_qtransform\": [t * 1000, f, np.array(H_hq).T],\n",
    "                    \"L_qtransform\": [t * 1000, f, np.array(L_hq).T],\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = 'plots/'\n",
    "try:\n",
    "    os.makedirs(savedir)\n",
    "except FileExistsError:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_start_times = [ 1251009253.724]\n",
    "# [(1239155734.182, -1.1),\n",
    "# (1240878400.307, -2.31),\n",
    "# (1241104246.749, -1.8),\n",
    "# (1241624696.55, -1.03),\n",
    "# (1242442957.423, -2.69),\n",
    "# (1242459847.413, -1.12),\n",
    "# (1242827473.37, -1.13),\n",
    "# (1243305662.931, -6.0),\n",
    "# (1245998824.997, -1.03),\n",
    "# (1246417246.823, -1.21),\n",
    "# (1246487209.308, -3.59),\n",
    "# (1247281292.53, -1.01),\n",
    "# (1248280604.554, -1.11),\n",
    "# (1249035984.212, -1.35),\n",
    "# (1249635282.359, -1.49),\n",
    "# (1250981809.437, -1.4),\n",
    "# (1251009253.724, -4.76),\n",
    "# (1252679441.276, -1.09),\n",
    "# (1252833818.202, -1.11),\n",
    "# (1253638396.336, -1.4),\n",
    "# (1257416710.328, -1.21),\n",
    "# (1260164266.18, -1.1),\n",
    "# (1260358297.149, -1.01),\n",
    "# (1260825537.025, -1.75),\n",
    "# (1261020945.101, -1.03),\n",
    "# (1262203609.392, -3.98),\n",
    "# (1263013357.045, -6.49),\n",
    "# (1264316106.385, -1.55),\n",
    "# (1264683185.946, -1.04),\n",
    "# (1266473981.889, -1.02),\n",
    "# (1267610448.007, -1.92),\n",
    "# (1267610483.017, -6.13),\n",
    "# (1267617688.034, -5.61),\n",
    "# (1267878076.354, -5.74),\n",
    "# (1269242528.39, -2.0)]\n",
    "\n",
    "\n",
    "# [    # 1251009253.724, # Loudest BBH\n",
    "    # 1249529264.698, # Loudest non-BBH\n",
    "    # 1263013367.055, # Lo dudest Cat2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting, 1251009253\n",
      "N splits: 2\n",
      "0 14745600\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([np\u001b[38;5;241m.\u001b[39marray(H\u001b[38;5;241m.\u001b[39mdata), np\u001b[38;5;241m.\u001b[39marray(L\u001b[38;5;241m.\u001b[39mdata)])\n\u001b[1;32m     12\u001b[0m base \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3554.75\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mget_evals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrained_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msavedir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHclean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLclean\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmanual_eval_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#[base])\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[45], line 31\u001b[0m, in \u001b[0;36mget_evals\u001b[0;34m(data_, model_path, savedir, start_point, gwpy_timeseries, neworder_clean, neworder_raw, manual_eval_times, metric)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m model_types:\n\u001b[1;32m     29\u001b[0m     model_paths\u001b[38;5;241m.\u001b[39mappend(model_path \u001b[38;5;241m+\u001b[39m elem)\n\u001b[0;32m---> 31\u001b[0m gwak_models \u001b[38;5;241m=\u001b[39m \u001b[43mload_gwak_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGPU_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m norm_factors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/katya.govorkova/gwak-paper-final-models/trained/norm_factor_params.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m fm_model_path \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/katya.govorkova/gwak-paper-final-models/trained/fm_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/gw-anomaly/gw_anomaly/scripts/helper_functions.py:186\u001b[0m, in \u001b[0;36mload_gwak_models\u001b[0;34m(model_path, device, device_name, load_precomputed_RNN, batch_size)\u001b[0m\n\u001b[1;32m    182\u001b[0m         model \u001b[38;5;241m=\u001b[39m LSTM_AE_SPLIT_use_precomputed(num_ifos\u001b[38;5;241m=\u001b[39mNUM_IFOS,\n\u001b[1;32m    183\u001b[0m                         num_timesteps\u001b[38;5;241m=\u001b[39mSEG_NUM_TIMESTEPS,\n\u001b[1;32m    184\u001b[0m                         BOTTLENECK\u001b[38;5;241m=\u001b[39mBOTTLENECK[model_name], batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43mLSTM_AE_SPLIT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_ifos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_IFOS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnum_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEG_NUM_TIMESTEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mBOTTLENECK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBOTTLENECK\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m MODEL[model_name] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    191\u001b[0m     model \u001b[38;5;241m=\u001b[39m FAT(num_ifos\u001b[38;5;241m=\u001b[39mNUM_IFOS,\n\u001b[1;32m    192\u001b[0m                 num_timesteps\u001b[38;5;241m=\u001b[39mSEG_NUM_TIMESTEPS,\n\u001b[1;32m    193\u001b[0m                 BOTTLENECK\u001b[38;5;241m=\u001b[39mBOTTLENECK[model_name])\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/quak/lib/python3.9/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quak/lib/python3.9/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/quak/lib/python3.9/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/quak/lib/python3.9/site-packages/torch/nn/modules/rnn.py:217\u001b[0m, in \u001b[0;36mRNNBase._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weight_refs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 217\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecurse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# Resets _flat_weights\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# Note: be v. careful before removing this, as 3rd party device types\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# likely rely on this behavior to properly .to() modules like LSTM.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_flat_weights()\n",
      "File \u001b[0;32m~/miniconda3/envs/quak/lib/python3.9/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/quak/lib/python3.9/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "trained_path = \"/home/katya.govorkova/gwak-paper-final-models/trained/models/\"\n",
    "\n",
    "for A in anomaly_start_times:\n",
    "    A = int(float(A))\n",
    "    B = A + 3600\n",
    "    print(\"starting,\", A)\n",
    "    H, L = whiten_bandpass_resample_new_order(A, B)\n",
    "\n",
    "    Hclean, Lclean = whiten_bandpass_resample(A, B)\n",
    "    data = np.vstack([np.array(H.data), np.array(L.data)])\n",
    "\n",
    "    base = 3554.75\n",
    "    get_evals(data, trained_path, savedir, int(A), [Hclean, Lclean],\n",
    "              manual_eval_times= None) #[base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd79c838-c15d-47bd-bb0c-a6455d015968",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gw-anomaly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/n/home00/emoreno/gw-anomaly/local-infer.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin.rc.fas.harvard.edu/n/home00/emoreno/gw-anomaly/local-infer.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mml4gw\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m ShiftedPearsonCorrelation, SpectralDensity, Whiten\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin.rc.fas.harvard.edu/n/home00/emoreno/gw-anomaly/local-infer.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mml4gw\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mslicing\u001b[39;00m \u001b[39mimport\u001b[39;00m unfold_windows\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blogin.rc.fas.harvard.edu/n/home00/emoreno/gw-anomaly/local-infer.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m model_lib \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39mgw-anomaly.scripts.models\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin.rc.fas.harvard.edu/n/home00/emoreno/gw-anomaly/local-infer.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m config \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39mgw-anomaly.config\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin.rc.fas.harvard.edu/n/home00/emoreno/gw-anomaly/local-infer.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m DATA_DIR \u001b[39m=\u001b[39m Path(\u001b[39m\"\u001b[39m\u001b[39m/n/home00/emoreno/gw-anomaly/output/O3av2/1243382418_1248652818/\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gwak/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:972\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:972\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gw-anomaly'"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import sys\n",
    "sys.path.append('./ml4gw')\n",
    "sys.path.append('./gw-anomaly')\n",
    "\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from ml4gw.transforms import ShiftedPearsonCorrelation, SpectralDensity, Whiten\n",
    "from ml4gw.utils.slicing import unfold_windows\n",
    "\n",
    "\n",
    "model_lib = importlib.import_module(\"scripts.models\")\n",
    "config = importlib.import_module(\"config\")\n",
    "\n",
    "DATA_DIR = Path(\"/n/home00/emoreno/gw-anomaly/output/O3av2/1243382418_1248652818/\")\n",
    "MODEL_DIR = Path(\"output/gwak-paper-final-models/trained/models/\")\n",
    "DEVICE = \"cuda:0\"\n",
    "SAMPLE_RATE = config.SAMPLE_RATE\n",
    "HIGHPASS = config.BANDPASS_LOW\n",
    "WINDOW_LENGTH = config.SEG_NUM_TIMESTEPS / config.SAMPLE_RATE\n",
    "STRIDE = (config.SEG_NUM_TIMESTEPS - config.SEGMENT_OVERLAP) / config.SAMPLE_RATE\n",
    "PSD_LENGTH = 64\n",
    "FDURATION = 2\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "\n",
    "def data_iterator(dataset: h5py.Dataset, shifts: list[float], batch_size: int = BATCH_SIZE):\n",
    "    shift_sizes = [int(i * SAMPLE_RATE) for i in shifts]\n",
    "    num_channels, size = dataset.shape\n",
    "\n",
    "    size -= max(shift_sizes)\n",
    "    stride_size = int(STRIDE * SAMPLE_RATE)\n",
    "    num_updates = size // stride_size\n",
    "    num_batches = int(num_updates // batch_size)\n",
    "\n",
    "    update_size = stride_size * batch_size\n",
    "    idx = np.arange(update_size)\n",
    "    x = np.zeros((num_channels, update_size))\n",
    "    for i in range(num_batches):\n",
    "        for j in range(num_channels):\n",
    "            start = i + update_size + shift_sizes[j]\n",
    "            stop = start + update_size\n",
    "            x[j] = dataset[j, start: stop]\n",
    "        yield torch.Tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42154de0-1aec-402a-b863-dcae88557680",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_channels: int,\n",
    "        sample_rate: float,\n",
    "        kernel_length: float,\n",
    "        fftlength: float,\n",
    "        fduration: float,\n",
    "        psd_length: float,\n",
    "        inference_sampling_rate: float,\n",
    "        highpass: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.spectral_density = SpectralDensity(\n",
    "            sample_rate=SAMPLE_RATE,\n",
    "            fftlength=fftlength,\n",
    "            overlap=None,  # defaults to fftlength / 2\n",
    "            average=\"median\",\n",
    "            fast=True  # not accurate for lowest 2 frequency bins, but we don't care about those\n",
    "        )\n",
    "        self.whitener = Whiten(\n",
    "            fduration=fduration,\n",
    "            sample_rate=sample_rate,\n",
    "            highpass=highpass\n",
    "        )\n",
    "\n",
    "        self.step_size = int(sample_rate / inference_sampling_rate)\n",
    "        self.kernel_size = int(kernel_length * sample_rate)\n",
    "        self.fsize = int(fduration * sample_rate)\n",
    "        self.psd_size = int(psd_length * sample_rate)\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self.psd_size + self.kernel_size + self.fsize - self.step_size\n",
    "\n",
    "    def get_initial_state(self):\n",
    "        return torch.zeros((self.num_channels, self.state_size))\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        state = torch.cat([state, X], dim=-1)\n",
    "        split = [self.psd_size, state.size(-1) - self.psd_size]\n",
    "        whiten_background, X = torch.split(state, split, dim=-1)\n",
    "\n",
    "        # only use the PSD of the non-injected data for computing\n",
    "        # our whitening to avoid biasing our PSD estimate\n",
    "        psd = self.spectral_density(whiten_background.double())\n",
    "        X = self.whitener(X, psd)\n",
    "        X = unfold_windows(X, self.kernel_size, self.step_size)\n",
    "        X = X.reshape(-1, self.num_channels, self.kernel_size)\n",
    "\n",
    "        # divide by standard deviation along time axis\n",
    "        X = X / X.std(axis=-1, keepdims=True)\n",
    "        return X, state[:, -self.state_size :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61932480-befc-4bc2-ac54-66b9274a8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = BatchGenerator(\n",
    "    num_channels=2,\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    kernel_length=WINDOW_LENGTH,\n",
    "    fftlength=2,\n",
    "    fduration=FDURATION,\n",
    "    psd_length=PSD_LENGTH,\n",
    "    inference_sampling_rate=1 / STRIDE,\n",
    "    highpass=HIGHPASS\n",
    ")\n",
    "batcher = batcher.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3da4eb8-1011-4201-9118-916754b3f107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: no corresponding model type for weights /home/katya.govorkova/gwak-paper-final-models/trained/models/sg.pt\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for fname in MODEL_DIR.glob(\"*.pt\"):\n",
    "    try:\n",
    "        model_type = config.MODEL[fname.stem]\n",
    "    except KeyError:\n",
    "        print(f\"WARNING: no corresponding model type for weights {fname}\")\n",
    "        continue\n",
    "\n",
    "    if model_type == \"lstm\":\n",
    "        model = model_lib.LSTM_AE_SPLIT(\n",
    "            num_ifos=config.NUM_IFOS,\n",
    "            num_timesteps=config.SEG_NUM_TIMESTEPS,\n",
    "            BOTTLENECK=config.BOTTLENECK[fname.stem]\n",
    "        )\n",
    "    elif model_type == \"dense\":\n",
    "        model = model_lib.FAT(\n",
    "            num_ifos=config.NUM_IFOS,\n",
    "            num_timesteps=config.SEG_NUM_TIMESTEPS,\n",
    "            BOTTLENECK=config.BOTTLENECK[fname.stem]\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(model_type)\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "    model.load_state_dict(torch.load(fname, map_location=DEVICE))\n",
    "    models[fname.stem] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92578386-37d3-4358-a3c0-bd0604008ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment\tDuration\tThroughput\n",
      "-------\t--------\t----------\n",
      "1243668368_1243671968\t3.25\t1083.09\n",
      "1243891850_1243895450\t3.19\t1105.68\n",
      "1244038423_1244042023\t3.20\t1102.42\n",
      "1244094823_1244098423\t3.23\t1092.99\n",
      "1244153226_1244156826\t3.23\t1092.62\n",
      "1244160426_1244164026\t3.23\t1092.97\n",
      "1244281375_1244284975\t3.25\t1085.78\n",
      "1244531604_1244535204\t3.31\t1065.92\n",
      "1244619591_1244623191\t3.23\t1091.32\n",
      "1244726076_1244729676\t3.38\t1043.40\n",
      "1244850228_1244853828\t3.32\t1061.06\n",
      "1244895499_1244899099\t3.24\t1086.40\n",
      "1244994812_1244998412\t3.30\t1068.22\n",
      "1245080336_1245083936\t3.20\t1100.15\n",
      "1245130314_1245133914\t3.22\t1095.05\n",
      "1245137514_1245141114\t3.62\t975.00\n",
      "1245480475_1245484075\t3.27\t1078.27\n",
      "1245889008_1245892608\t3.31\t1066.00\n",
      "1246014028_1246017628\t3.21\t1098.66\n",
      "1246160199_1246163799\t3.22\t1095.12\n",
      "1246338884_1246342484\t3.17\t1111.92\n",
      "1246510744_1246514344\t3.19\t1105.39\n",
      "1246576222_1246579822\t3.18\t1107.28\n",
      "1246637934_1246641534\t3.22\t1094.81\n",
      "1247366989_1247370589\t3.25\t1084.13\n",
      "1247407441_1247411041\t3.23\t1092.94\n",
      "1247442440_1247446040\t3.20\t1102.12\n",
      "1247473688_1247477288\t3.33\t1058.53\n",
      "1247527846_1247531446\t3.26\t1080.94\n",
      "1247867407_1247871007\t3.24\t1089.56\n",
      "1248139301_1248142901\t3.20\t1100.31\n",
      "1248174783_1248178383\t3.21\t1096.96\n",
      "1248178383_1248181983\t3.24\t1089.48\n",
      "1248207738_1248211338\t3.25\t1085.09\n",
      "1248379425_1248383025\t3.21\t1097.93\n",
      "1248522234_1248525834\t3.27\t1077.39\n"
     ]
    }
   ],
   "source": [
    "# build a Pearson correlation that we can evaluate\n",
    "# alongside the rest of our models\n",
    "pearson = ShiftedPearsonCorrelation(int(0.01 * SAMPLE_RATE))\n",
    "SHIFT = [0, 1]\n",
    "\n",
    "# here's some gross logic for pretty printing, don't worry about this\n",
    "columns = [\"Segment\", \"Duration (s)\", \"Throughput (s' / s)\"]\n",
    "tabs = [3, 1, 0]\n",
    "print(*[i + \"\\t\" * j for i, j in zip(columns, tabs)])\n",
    "print(*[\"-\" * len(i) + \"\\t\" * j for i, j in zip(columns, tabs)])\n",
    "\n",
    "with torch.no_grad(), h5py.File(\"background.hdf5\", \"r\") as f:\n",
    "    # iterate through all the datasets in our archive\n",
    "    for segment, dataset in f.items():\n",
    "        start_time = time.time()\n",
    "\n",
    "        # initialize a container for our predictions\n",
    "        # and create an initial blank snapshot state.\n",
    "        # The most efficient way to do this would be\n",
    "        # to allocate all the memory up front since\n",
    "        # we know how many steps to take, but this\n",
    "        # will work for the time being.\n",
    "        predictions = defaultdict(list)\n",
    "        state = batcher.get_initial_state().to(DEVICE)\n",
    "        num_preds = 0\n",
    "        for x in data_iterator(dataset, SHIFT):\n",
    "            # move the timeseries onto the GPU, then update our\n",
    "            # state and perform preprocessing\n",
    "            x = x.to(DEVICE)\n",
    "            X, state = batcher(x, state)\n",
    "\n",
    "            # feed the preprocessed data through each one of our models\n",
    "            for name, model in models.items():\n",
    "                y = model(X)\n",
    "                loss = (y - X)**2\n",
    "                loss = loss.mean(dim=[1, 2])\n",
    "                predictions[model].append(loss.cpu().numpy())\n",
    "\n",
    "            # compute the pearson correlation between\n",
    "            # both interferometer channels\n",
    "            corr = pearson(X[:, :1], X[:, 1:])\n",
    "            corr = corr.max(dim=0).values[:, 0].cpu().numpy()\n",
    "            predictions[\"pearson\"].append(corr)\n",
    "\n",
    "            num_preds += len(X)\n",
    "\n",
    "        # concatenate everything back on the CPU then click our stopwatch\n",
    "        predictions = {k: np.concatenate(v) for k, v in predictions.items()}\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        throughput = num_preds * STRIDE / duration\n",
    "\n",
    "        # more pretty printing, continue not worrying about it\n",
    "        duration, throughput = [f\"{i:0.2f}\" for i in [duration, throughput]]\n",
    "        tabs = [1, 2, 0]\n",
    "        print(*[i + \"\\t\" * j for i, j in zip([segment, duration, throughput], tabs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08647157-d416-4bcb-85d8-c53ab8aa44d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
